#!/usr/bin/env python
"""
Comprehensive test script for Sprint 7 - Admin Dashboard & Export Logs.

This script demonstrates:
1. All 7 types of analytics logging
2. CSV export functionality
3. Admin dashboard analytics
4. Level transition policies
5. Q-Learning performance tracking
6. User engagement metrics
7. Success rate calculations
"""

import os
import sys
import django
import json
from datetime import timedelta

# Setup Django
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'gamify_ai.settings')
django.setup()

from django.contrib.auth import get_user_model
from accounts.models import StudentProfile
from quizzes.models import Question, AttemptLog
from qlearning.models import (
    UserEngagementLog, SuccessRateLog, ResponseToAdaptationLog,
    QLearningPerformanceLog, LevelTransitionLog, RewardIncentivesLog, GlobalSystemLog,
    QTableEntry, QLearningLog
)
from qlearning.analytics import AnalyticsService
from qlearning.policies import LevelTransitionPolicy

User = get_user_model()


def create_comprehensive_test_data():
    """Create comprehensive test data for all analytics features."""
    print("ğŸ§ª Creating comprehensive test data...")

    # Create test user
    user, created = User.objects.get_or_create(
        username='analytics_test_user',
        defaults={
            'email': 'analytics@example.com',
            'role': 'student'
        }
    )
    if created:
        user.set_password('testpass123')
        user.save()
        print(f"âœ… Created user: {user.username}")

    # Create or get profile
    profile, created = StudentProfile.objects.get_or_create(
        user=user,
        defaults={
            'level': 'beginner',
            'points': 0,
            'streak_correct': 0,
            'progress': 0,
            'last_difficulty': 'easy'
        }
    )
    if created:
        print(f"âœ… Created profile for: {user.username}")

    # Create comprehensive test questions
    questions_data = [
        # Easy questions (15)
        {'text': 'What is 2 + 2?', 'difficulty': 'easy', 'format': 'mcq_simple', 'options': {'A': '3', 'B': '4', 'C': '5'}, 'answer_key': 'B', 'curriculum_tag': 'Mathematics'},
        {'text': 'What color is the sky?', 'difficulty': 'easy', 'format': 'mcq_simple', 'options': {'A': 'Green', 'B': 'Blue', 'C': 'Red'}, 'answer_key': 'B', 'curriculum_tag': 'Science'},
        {'text': 'What is 1 + 1?', 'difficulty': 'easy', 'format': 'mcq_simple', 'options': {'A': '1', 'B': '2', 'C': '3'}, 'answer_key': 'B', 'curriculum_tag': 'Mathematics'},
        {'text': 'How many legs does a cat have?', 'difficulty': 'easy', 'format': 'mcq_simple', 'options': {'A': '2', 'B': '4', 'C': '6'}, 'answer_key': 'B', 'curriculum_tag': 'Science'},
        {'text': 'What comes after Monday?', 'difficulty': 'easy', 'format': 'mcq_simple', 'options': {'A': 'Sunday', 'B': 'Tuesday', 'C': 'Wednesday'}, 'answer_key': 'B', 'curriculum_tag': 'General'},
        {'text': 'What is 3 + 3?', 'difficulty': 'easy', 'format': 'mcq_simple', 'options': {'A': '5', 'B': '6', 'C': '7'}, 'answer_key': 'B', 'curriculum_tag': 'Mathematics'},
        {'text': 'What animal says "meow"?', 'difficulty': 'easy', 'format': 'mcq_simple', 'options': {'A': 'Dog', 'B': 'Cat', 'C': 'Bird'}, 'answer_key': 'B', 'curriculum_tag': 'Science'},
        {'text': 'What is the first letter of the alphabet?', 'difficulty': 'easy', 'format': 'mcq_simple', 'options': {'A': 'B', 'B': 'A', 'C': 'C'}, 'answer_key': 'B', 'curriculum_tag': 'Language'},
        {'text': 'How many wheels does a car have?', 'difficulty': 'easy', 'format': 'mcq_simple', 'options': {'A': '3', 'B': '4', 'C': '5'}, 'answer_key': 'B', 'curriculum_tag': 'General'},
        {'text': 'What shape is a stop sign?', 'difficulty': 'easy', 'format': 'mcq_simple', 'options': {'A': 'Square', 'B': 'Octagon', 'C': 'Triangle'}, 'answer_key': 'B', 'curriculum_tag': 'General'},
        {'text': 'What is 4 + 4?', 'difficulty': 'easy', 'format': 'mcq_simple', 'options': {'A': '6', 'B': '8', 'C': '10'}, 'answer_key': 'B', 'curriculum_tag': 'Mathematics'},
        {'text': 'What do bees make?', 'difficulty': 'easy', 'format': 'mcq_simple', 'options': {'A': 'Milk', 'B': 'Honey', 'C': 'Juice'}, 'answer_key': 'B', 'curriculum_tag': 'Science'},
        {'text': 'What is 5 + 5?', 'difficulty': 'easy', 'format': 'mcq_simple', 'options': {'A': '8', 'B': '10', 'C': '12'}, 'answer_key': 'B', 'curriculum_tag': 'Mathematics'},
        {'text': 'What color are bananas?', 'difficulty': 'easy', 'format': 'mcq_simple', 'options': {'A': 'Red', 'B': 'Yellow', 'C': 'Blue'}, 'answer_key': 'B', 'curriculum_tag': 'Science'},
        {'text': 'What is 6 + 6?', 'difficulty': 'easy', 'format': 'mcq_simple', 'options': {'A': '10', 'B': '12', 'C': '14'}, 'answer_key': 'B', 'curriculum_tag': 'Mathematics'},

        # Medium questions (10)
        {'text': 'What is the capital of France?', 'difficulty': 'medium', 'format': 'mcq_simple', 'options': {'A': 'London', 'B': 'Berlin', 'C': 'Paris'}, 'answer_key': 'C', 'curriculum_tag': 'Geography'},
        {'text': 'What is 15 Ã— 8?', 'difficulty': 'medium', 'format': 'mcq_simple', 'options': {'A': '120', 'B': '115', 'C': '125'}, 'answer_key': 'A', 'curriculum_tag': 'Mathematics'},
        {'text': 'Who wrote Romeo and Juliet?', 'difficulty': 'medium', 'format': 'mcq_simple', 'options': {'A': 'Shakespeare', 'B': 'Dickens', 'C': 'Austen'}, 'answer_key': 'A', 'curriculum_tag': 'Literature'},
        {'text': 'What is the largest planet in our solar system?', 'difficulty': 'medium', 'format': 'mcq_simple', 'options': {'A': 'Earth', 'B': 'Jupiter', 'C': 'Saturn'}, 'answer_key': 'B', 'curriculum_tag': 'Science'},
        {'text': 'In which year did World War II end?', 'difficulty': 'medium', 'format': 'mcq_simple', 'options': {'A': '1944', 'B': '1945', 'C': '1946'}, 'answer_key': 'B', 'curriculum_tag': 'History'},
        {'text': 'What is 25 Ã— 4?', 'difficulty': 'medium', 'format': 'mcq_simple', 'options': {'A': '100', 'B': '90', 'C': '110'}, 'answer_key': 'A', 'curriculum_tag': 'Mathematics'},
        {'text': 'What is the chemical symbol for gold?', 'difficulty': 'medium', 'format': 'mcq_simple', 'options': {'A': 'Go', 'B': 'Gd', 'C': 'Au'}, 'answer_key': 'C', 'curriculum_tag': 'Chemistry'},
        {'text': 'Who painted the Mona Lisa?', 'difficulty': 'medium', 'format': 'mcq_simple', 'options': {'A': 'Van Gogh', 'B': 'Da Vinci', 'C': 'Picasso'}, 'answer_key': 'B', 'curriculum_tag': 'Art'},
        {'text': 'What is the square root of 144?', 'difficulty': 'medium', 'format': 'mcq_simple', 'options': {'A': '12', 'B': '14', 'C': '16'}, 'answer_key': 'A', 'curriculum_tag': 'Mathematics'},
        {'text': 'What gas do plants absorb from the atmosphere?', 'difficulty': 'medium', 'format': 'mcq_simple', 'options': {'A': 'Oxygen', 'B': 'Nitrogen', 'C': 'Carbon Dioxide'}, 'answer_key': 'C', 'curriculum_tag': 'Biology'},

        # Hard questions (5)
        {'text': 'What is the chemical formula for glucose?', 'difficulty': 'hard', 'format': 'short_answer', 'options': None, 'answer_key': 'C6H12O6', 'curriculum_tag': 'Chemistry'},
        {'text': 'Explain Newton\'s First Law of Motion.', 'difficulty': 'hard', 'format': 'short_answer', 'options': None, 'answer_key': 'An object at rest stays at rest', 'curriculum_tag': 'Physics'},
        {'text': 'What is the derivative of sin(x)?', 'difficulty': 'hard', 'format': 'short_answer', 'options': None, 'answer_key': 'cos(x)', 'curriculum_tag': 'Mathematics'},
        {'text': 'In what year was the United Nations founded?', 'difficulty': 'hard', 'format': 'mcq_simple', 'options': {'A': '1944', 'B': '1945', 'C': '1946'}, 'answer_key': 'B', 'curriculum_tag': 'History'},
        {'text': 'What is the atomic number of carbon?', 'difficulty': 'hard', 'format': 'mcq_simple', 'options': {'A': '6', 'B': '8', 'C': '12'}, 'answer_key': 'A', 'curriculum_tag': 'Chemistry'},
    ]

    created_questions = []
    for q_data in questions_data:
        question, created = Question.objects.get_or_create(
            text=q_data['text'],
            defaults=q_data
        )
        if created:
            print(f"âœ… Created {question.difficulty} question: {question.text[:40]}...")
        created_questions.append(question)

    return user, profile, created_questions


def test_user_engagement_logging():
    """Test user engagement logging functionality."""
    print("\nğŸ§ª Testing User Engagement Logging...")

    user, profile, questions = create_comprehensive_test_data()

    # Log different types of user engagement
    AnalyticsService.log_user_engagement(
        user=user,
        session_type='login',
        duration_seconds=300,
        questions_attempted=0,
        hints_used=0,
        gamification_interactions=1,
        metadata={'ip_address': '127.0.0.1', 'user_agent': 'test'}
    )

    AnalyticsService.log_user_engagement(
        user=user,
        session_type='quiz_attempt',
        duration_seconds=600,
        questions_attempted=5,
        hints_used=2,
        gamification_interactions=3,
        metadata={'quiz_topic': 'mathematics', 'difficulty': 'easy'}
    )

    AnalyticsService.log_user_engagement(
        user=user,
        session_type='level_claim',
        duration_seconds=120,
        questions_attempted=0,
        hints_used=0,
        gamification_interactions=2,
        metadata={'old_level': 'beginner', 'new_level': 'intermediate'}
    )

    # Check logged data
    engagement_logs = UserEngagementLog.objects.filter(user=user)
    print(f"âœ… Created {engagement_logs.count()} engagement logs")

    for log in engagement_logs:
        print(f"  â€¢ {log.session_type}: {log.duration_seconds}s, {log.questions_attempted} questions, {log.hints_used} hints")

    return user, profile, questions


def test_success_rate_logging():
    """Test success rate logging functionality."""
    print("\nğŸ§ª Testing Success Rate Logging...")

    user, profile, questions = create_comprehensive_test_data()

    # Create some quiz attempts to generate success rate data
    from quizzes.services import QuizService

    # Answer 12 easy questions correctly (should be enough for level up)
    for i in range(12):
        question = questions[i]  # First 12 are easy questions
        result = QuizService.record_attempt(
            profile=profile,
            question=question,
            chosen_answer='B',  # Correct answer for all easy questions
            time_spent=30.0
        )

    # Log success rates for different difficulties
    for difficulty in ['easy', 'medium', 'hard']:
        AnalyticsService.log_success_rate(user, difficulty, time_window_days=7)

    # Check logged data
    success_logs = SuccessRateLog.objects.filter(user=user)
    print(f"âœ… Created {success_logs.count()} success rate logs")

    for log in success_logs:
        print(f"  â€¢ {log.difficulty}: {log.correct_attempts}/{log.total_attempts} ({log.accuracy_percentage:.1f}%)")

    return user, profile, questions


def test_level_transition_logging():
    """Test level transition logging functionality."""
    print("\nğŸ§ª Testing Level Transition Logging...")

    user, profile, questions = create_comprehensive_test_data()

    # Create some quiz attempts to generate success rate data
    from quizzes.services import QuizService

    # Answer 12 easy questions correctly (should be enough for level up)
    for i in range(12):
        question = questions[i]  # First 12 are easy questions
        result = QuizService.record_attempt(
            profile=profile,
            question=question,
            chosen_answer='B',  # Correct answer for all easy questions
            time_spent=30.0
        )

    # Check if user can level up
    can_level_up, target_level = LevelTransitionPolicy.can_level_up(profile)

    if can_level_up and target_level:
        print(f"âœ… User can level up from {profile.level} to {target_level}")

        # Log the level transition
        AnalyticsService.log_level_transition(
            user=user,
            transition_type='level_up_manual',
            old_level=profile.level,
            new_level=target_level,
            transition_condition={
                'easy_correct': 12,
                'easy_total': 12,
                'threshold_met': True,
                'required_percentage': 70.0
            },
            performance_metrics={
                'overall_accuracy': 100.0,
                'streak': profile.streak_correct,
                'points': profile.points
            }
        )

        print(f"âœ… Logged level transition: {profile.level} â†’ {target_level}")
    else:
        print(f"âŒ User cannot level up yet")

    # Check logged data
    transition_logs = LevelTransitionLog.objects.filter(user=user)
    print(f"âœ… Created {transition_logs.count()} level transition logs")

    for log in transition_logs:
        print(f"  â€¢ {log.old_level} â†’ {log.new_level} ({log.transition_type})")

    return user, profile, questions


def test_reward_logging():
    """Test reward and incentives logging functionality."""
    print("\nğŸ§ª Testing Reward & Incentives Logging...")

    user, profile, questions = create_comprehensive_test_data()

    # Log different types of rewards
    AnalyticsService.log_reward_incentive(
        user=user,
        reward_type='points',
        reward_value=10.0,
        trigger_condition={'reason': 'correct_answer', 'streak': 1},
        user_reaction={'continued': True, 'time_spent_after': 45},
        session_continuation=True
    )

    AnalyticsService.log_reward_incentive(
        user=user,
        reward_type='streak_bonus',
        reward_value=10.0,
        trigger_condition={'reason': 'streak_reached', 'streak_count': 3},
        user_reaction={'continued': True, 'attempts_after': 5},
        session_continuation=True
    )

    AnalyticsService.log_reward_incentive(
        user=user,
        reward_type='hidden_reward',
        reward_value=10.0,
        trigger_condition={'reason': 'level_up_milestone', 'level': 'intermediate'},
        user_reaction={'continued': False, 'session_ended': True},
        session_continuation=False
    )

    # Check logged data
    reward_logs = RewardIncentivesLog.objects.filter(user=user)
    print(f"âœ… Created {reward_logs.count()} reward logs")

    for log in reward_logs:
        print(f"  â€¢ {log.reward_type}: {log.reward_value} points, continued: {log.session_continuation}")

    return user, profile, questions


def test_qlearning_performance_logging():
    """Test Q-Learning performance logging functionality."""
    print("\nğŸ§ª Testing Q-Learning Performance Logging...")

    user, profile, questions = create_comprehensive_test_data()

    # Create some quiz attempts to generate Q-Learning data
    from quizzes.services import QuizService

    # Answer some questions to generate Q-Learning logs
    for i in range(5):
        question = questions[i]  # First 5 questions
        result = QuizService.record_attempt(
            profile=profile,
            question=question,
            chosen_answer='B',  # Correct answer
            time_spent=30.0
        )

    # Log Q-Learning performance
    AnalyticsService.log_qlearning_performance(user)

    # Check logged data
    qlearning_logs = QLearningPerformanceLog.objects.filter(user=user)
    print(f"âœ… Created {qlearning_logs.count()} Q-Learning performance logs")

    for log in qlearning_logs:
        print(f"  â€¢ Optimal actions: {log.optimal_action_frequency:.2f}, Avg Q: {log.average_q_value:.3f}, Table size: {log.q_table_size}")

    return user, profile, questions


def test_global_system_logging():
    """Test global system logging functionality."""
    print("\nğŸ§ª Testing Global System Logging...")

    user, profile, questions = create_comprehensive_test_data()

    # Create some quiz attempts to generate global data
    from quizzes.services import QuizService

    for i in range(5):
        question = questions[i]
        result = QuizService.record_attempt(
            profile=profile,
            question=question,
            chosen_answer='B',
            time_spent=30.0
        )

    # Log global system metrics
    AnalyticsService.log_global_system_metrics('accuracy_global', 'daily')
    AnalyticsService.log_global_system_metrics('engagement_daily', 'daily')
    AnalyticsService.log_global_system_metrics('hint_distribution', 'daily')
    AnalyticsService.log_global_system_metrics('qlearning_trend', 'daily')

    # Check logged data
    global_logs = GlobalSystemLog.objects.all()
    print(f"âœ… Created {global_logs.count()} global system logs")

    for log in global_logs:
        print(f"  â€¢ {log.metric_type} ({log.time_window}): {log.metric_data.get('total_attempts', 'N/A')} total attempts")

    return user, profile, questions


def test_csv_exports():
    """Test CSV export functionality."""
    print("\nğŸ§ª Testing CSV Export Functionality...")

    user, profile, questions = test_global_system_logging()

    # Test all export functions
    export_functions = [
        ('engagement', UserEngagementLog),
        ('success', SuccessRateLog),
        ('transitions', LevelTransitionLog),
        ('rewards', RewardIncentivesLog),
        ('qlearning', QLearningLog),
        ('qlearning_performance', QLearningPerformanceLog),
        ('global', GlobalSystemLog),
    ]

    for export_name, model_class in export_functions:
        if hasattr(model_class, 'user'):
            # Models with user field
            count = model_class.objects.filter(user=user).count()
        else:
            # Models without user field (like GlobalSystemLog)
            count = model_class.objects.count()
        if count > 0:
            print(f"âœ… {export_name} logs: {count} records ready for export")
        else:
            print(f"âš ï¸  {export_name} logs: No data to export")

    return user, profile, questions


def test_comprehensive_dashboard():
    """Test comprehensive dashboard data generation."""
    print("\nğŸ§ª Testing Comprehensive Dashboard Data...")

    user, profile, questions = test_csv_exports()

    # Get comprehensive dashboard data
    dashboard_data = AnalyticsService.get_comprehensive_dashboard_data()

    print("âœ… Dashboard data generated successfully:")
    print(f"  â€¢ Engagement: {dashboard_data['engagement']['total_sessions']} sessions")
    print(f"  â€¢ Success: {dashboard_data['success']['overall_accuracy']:.1f}% accuracy")
    print(f"  â€¢ Transitions: {dashboard_data['transitions']['total_transitions']} transitions")
    print(f"  â€¢ Q-Learning: {dashboard_data['qlearning']['total_updates']} updates")
    print(f"  â€¢ Global: {dashboard_data['global']['latest_accuracy']:.1f}% latest accuracy")

    return user, profile, questions


def run_comprehensive_analytics_test():
    """Run all analytics tests in sequence."""
    print("=" * 80)
    print("ğŸ§  COMPREHENSIVE ANALYTICS SYSTEM TEST")
    print("=" * 80)

    try:
        # Run all test functions
        test_user_engagement_logging()
        test_success_rate_logging()
        test_level_transition_logging()
        test_reward_logging()
        test_qlearning_performance_logging()
        test_global_system_logging()
        test_csv_exports()
        test_comprehensive_dashboard()

        print("\n" + "=" * 80)
        print("âœ… ALL ANALYTICS TESTS COMPLETED SUCCESSFULLY!")
        print("=" * 80)

        # Summary
        print("\nğŸ“Š ANALYTICS SYSTEM SUMMARY:")
        print("âœ… User Engagement Logging - Tracks session metrics, hints, gamification")
        print("âœ… Success Rate Logging - Monitors accuracy per difficulty over time")
        print("âœ… Level Transition Logging - Records level up/down with conditions")
        print("âœ… Reward & Incentives Logging - Tracks effectiveness of rewards")
        print("âœ… Q-Learning Performance Logging - Monitors algorithm learning")
        print("âœ… Global System Logging - Provides macro-level statistics")
        print("âœ… CSV Export Functionality - All logs exportable to CSV")
        print("âœ… Comprehensive Dashboard - Real-time analytics display")

        print("\nğŸ¯ LOG TYPES IMPLEMENTED:")
        print("1. ğŸ“ˆ User Engagement Log - Login frequency, session duration, interactions")
        print("2. ğŸ¯ Success Rate Log - Accuracy per difficulty, time trends")
        print("3. ğŸ”„ Response to Adaptation Log - User reactions to system changes")
        print("4. ğŸ¤– Q-Learning Performance Log - Algorithm learning metrics")
        print("5. â¬†ï¸ Level Transition Log - Level progression tracking")
        print("6. ğŸ Reward & Incentives Log - Reward effectiveness analysis")
        print("7. ğŸŒ Global System Log - System-wide statistics")

        print("\nğŸ“‹ ADMIN DASHBOARD FEATURES:")
        print("â€¢ Real-time analytics cards with key metrics")
        print("â€¢ Detailed tables for each log type")
        print("â€¢ CSV export buttons for all log categories")
        print("â€¢ Comprehensive filtering and search")
        print("â€¢ Visual progress indicators")
        print("â€¢ Auto-refresh functionality")

        print("\nğŸ”— ADMIN INTERFACE:")
        print("â€¢ Django admin integration for all log models")
        print("â€¢ Advanced filtering and search capabilities")
        print("â€¢ Bulk operations support")
        print("â€¢ Export functionality built-in")

    except Exception as e:
        print(f"\nâŒ TEST FAILED: {e}")
        import traceback
        traceback.print_exc()
        return False

    return True


if __name__ == '__main__':
    run_comprehensive_analytics_test()
